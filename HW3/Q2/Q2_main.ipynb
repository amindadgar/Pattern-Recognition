{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Using the bayes classifier and the parameters below for each data set, find the optimal class for data. ( Note: No training needed! )\n",
    "| Dataset | $\\mu_1$ | $\\mu_2$ | $\\sigma_{11}$ | $\\sigma_{12}$ | $\\sigma_{22}$ |\n",
    "| ------- | ------- | ------- | ------------- | ------------- | ------------- |\n",
    "| $A1$ | $0$ | $0$ | $1$ | $-0.8$ | $1$ |\n",
    "| $A2$ | $2$ | $2$ | $1$ | $0.8$ | $1$ |\n",
    "| $B1$ | $0$ | $0$ | $1$ | $-0.75$ | $1$ |\n",
    "| $B2$ | $0$ | $0$ | $1$ | $0.75$ | $1$ |\n",
    "| $C1$ | $0$ | $0$ | $1.75$ | $0$ | $0.25$ |\n",
    "| $C2$ | $0$ | $0$ | $0.25$ | $0$ | $1.75$ |\n",
    "| $D1$ | $0$ | $0$ | $1$ | $0$ | $1$ |\n",
    "| $D2$ | $0$ | $0$ | $9$ | $0$ | $9$ |\n",
    "| $E1$ | $0$ | $0$ | $3$ | $1$ | $0.5$ |\n",
    "| $E2$ | $-0.8$ | $0.8$ | $3$ | $1$ | $0.5$ |\n",
    "| $F1$ | $0$ | $0$ | $3$ | $1$ | $0.5$ |\n",
    "| $F2$ | $1$ | $6$ | $3$ | $1$ | $0.5$ |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know from bayes classifier we need to find the posterior of data using the equation below:\n",
    "$$\n",
    "\\begin{equation}\n",
    "p(x|c) = \\int p(x|\\theta) p(\\theta|c) d\\theta\n",
    "\\end{equation}\n",
    "$$\n",
    "*Note:* c is the class label. <br>\n",
    "but since the question gave us the $\\theta$ ( $\\mu$ and $\\sigma$ ), we can find the value of $p(x|D)$ using the guassian distribution below. <br>\n",
    "*Note*: we know that $p(x|D)$ is using the Gaussian distribution from the question.\n",
    "$$\n",
    "\\begin{equation}\n",
    "p(x|D^{class\\_no}) = N(\\mu^{class\\_no}, \\Sigma^{class\\_no})\n",
    "\\end{equation}\n",
    "$$\n",
    "And the Normal or Gaussian distribution formula for multivariate distributions is as below:\n",
    "$$\n",
    "\\begin{equation}\n",
    "N(\\mu^{class\\_no}, \\Sigma^{class\\_no}) = \\frac{1}{\\sqrt{2\\pi |\\Sigma|}} e^{ -\\frac{1}{2} (x-\\mu)^t \\Sigma^{-1} (x-\\mu)}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the covariance matrix is a symmetrical matrix we know that $\\sigma_{12} = \\sigma_{21}$, So we use this point to compute the covariance matrix ($\\Sigma$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the probability of x using the x value\n",
    "def guassian_multivariate(mu ,Sigma, x1, x2):\n",
    "    \"\"\"\n",
    "    calculate the probability of multivariate guassian\n",
    "    we have a feature space of 2 by 1\n",
    "\n",
    "    INPUTS:\n",
    "    --------\n",
    "    mu:  is the mean value \n",
    "    Sigma:  covariance matrix\n",
    "    x1:  feature one, a scalar value\n",
    "    x2:  feature two, a scalar value\n",
    "\n",
    "    OUTPUT:\n",
    "    -------\n",
    "    probability:  A scalar value representing the probability of X features \n",
    "    \"\"\"\n",
    "\n",
    "    coefficient = 1 / 2 * np.pi\n",
    "    ## inverse of covariance matrix\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "    ## the features array (transposing it to make it as 2 by 1 vector)\n",
    "    X = np.array([x1, x2]).T\n",
    "\n",
    "    ## exponential power value ( the superscript) \n",
    "    e_superscript =  (-1/2) * np.dot((X - mu).T , Sigma_inv ).dot(X) \n",
    "    \n",
    "    e = np.exp(e_superscript)\n",
    "\n",
    "    # covariance determanant\n",
    "    det_Sigma = np.linalg.det(Sigma)\n",
    "    probability = coefficient * np.sqrt(det_Sigma) * e\n",
    "\n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.29520456]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate the probability for the first data in A dataset\n",
    "\n",
    "## read the csv dataset\n",
    "ds_A = pd.read_csv('../processed_dataset/Atrain.csv')\n",
    "\n",
    "## cov matrix and mean vector for class 1\n",
    "A_Sigma1 = np.matrix('1 -0.8; -0.8 1')\n",
    "A_mu1 = np.array([0, 0])\n",
    "\n",
    "x1 = ds_A['feature_one'].iloc[0]\n",
    "x2 = ds_A['feature_two'].iloc[0]\n",
    "\n",
    "guassian_multivariate(A_mu1, A_Sigma1, x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.00240618]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cov matrix and mean vector for class 2\n",
    "A_Sigma2 = np.matrix('1 0.8; 0.8 1')\n",
    "A_mu2 = np.array([2, 2])\n",
    "\n",
    "guassian_multivariate(A_mu2, A_Sigma2, x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we have calculated posterior probability for the first data in Atrain dataset and we can see that the probability for class 1 is much more than class 2, So class one is the classified output and it can be seen as below it is the right class. (class 1 has the label 0 and class 2 has the label 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_A['label'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## capsulation of testing for all data\n",
    "Now we wil test the all above calculation for all data (In A dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cov matrix and mean vector for class 1\n",
    "A_Sigma1 = np.matrix('1 -0.8; -0.8 1')\n",
    "A_mu1 = np.array([0, 0])\n",
    "\n",
    "## cov matrix and mean vector for class 2\n",
    "A_Sigma2 = np.matrix('1 0.8; 0.8 1')\n",
    "A_mu2 = np.array([2, 2])\n",
    "\n",
    "## save the classified label for each data\n",
    "classified_labels = []\n",
    "for i in range(0, len(ds_A)):\n",
    "\n",
    "    x1 = ds_A['feature_one'].iloc[i]\n",
    "    x2 = ds_A['feature_two'].iloc[i]\n",
    "\n",
    "    ## calculate the probability for calss 1\n",
    "    p_class1 = guassian_multivariate(A_mu1, A_Sigma1, x1, x2)\n",
    "    ## calculate the probability for calss 2\n",
    "    p_class2 = guassian_multivariate(A_mu2, A_Sigma2, x1, x2)\n",
    "\n",
    "    ## class 2 has the label 1 (True)\n",
    "    ## class 1 has the label 0 (False)\n",
    "    label = p_class2 > p_class1\n",
    "\n",
    "    classified_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of correct classfied:  1790\n",
      "acc:  89.5 %\n"
     ]
    }
   ],
   "source": [
    "## check the correct classified labels\n",
    "correct_classified = (np.array(classified_labels).flatten() == ds_A.label).sum()\n",
    "print('count of correct classfied: ', correct_classified)\n",
    "print('acc: ', correct_classified / len(ds_A) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part A\n",
    "Calculate the classification accuracy using the bayes classifier and given information for A to F datasets. Also compare the results with ideal classifier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_confusion_matrix(actual_label, target_label):\n",
    "    \"\"\"\n",
    "    create the confusion matrix and accuracy and insert them into a pandas dataframe \n",
    "\n",
    "    INPUTS:\n",
    "    ---------\n",
    "    actual_label:  the label classified by the classifier\n",
    "    target_label:  the right labels for data from dataset\n",
    "\n",
    "    OUTPUT:\n",
    "    -----------\n",
    "    confusion_matrix:  A Dataset with with elements of TP, TN, FP, FN, accuarcy as True Positives, True Negatives, False Positives, False Negative, and classifier accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.array(actual_label)\n",
    "    t = np.array(target_label)\n",
    "    \n",
    "    TP = ((a == True) & (t == True)).sum()\n",
    "    TN = ((a == False) & (t == False)).sum()\n",
    "    FP = ((a == True) & (t == False)).sum()\n",
    "    FN = ((a == False) & (t == True)).sum()\n",
    " \n",
    "    confusion_matrix = pd.DataFrame(data={'TP':[TP], 'TN': [TN], 'FP': [FP], 'FN': [FN]})\n",
    "    confusion_matrix['accuracy'] = (a == t).sum() * 100 / len(actual_label)\n",
    "    \n",
    "    return confusion_matrix\n",
    "\n",
    "def bayes_classifier(datasets_name, mu_s, Sigma_s):\n",
    "    \"\"\"\n",
    "    use the bayes classifier for multiple datasets\n",
    "\n",
    "    INPUTS:\n",
    "    --------\n",
    "    datasets:  array of multiple datasets name\n",
    "    mu_s:  [mu1, mu2] multidimensional array, array of mean for class1 and class2 vectors for each dataset (Note each mu shape is 2*1)\n",
    "    Sigma_s:  [Sigma1, Sigma2] multidimensional array, array of covariance for class1 and class2 vectors for each dataset\n",
    "\n",
    "    OUTPUT:\n",
    "    --------\n",
    "    ds_results:  pandas dataframe of results containing dataset_name,confusion_matrix and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    ## check the values are correctly entered\n",
    "    assert len(datasets_name) == len(mu_s), 'Error! not enough mean array for datasets was given!\\ndatasets array length must be equal to mean (mu) array length '\n",
    "    assert len(Sigma_s) == len(mu_s), 'Error! not enough Sigma data for mu datas was given!\\ncovariance (Sigma) array length must be equal to mean array length '\n",
    "    assert len(Sigma_s) == len(datasets_name), 'Error! not enough Sigma data for datasets was given!\\ncovariance (Sigma) array length must be equal to dataset array length'\n",
    "\n",
    "    ## check all the parameters for each class was entered correctly!\n",
    "    ## the Sigma_s or the covariance array has the shape of 6 arrays and each array consist of two matrixes with 4 element (2 by 2 matrix) \n",
    "    assert len(Sigma_s.flatten()) == len(Sigma_s) * 2 * 4, 'Error! covariances for each class was not entered correctly!\\nSigma_s shape is 6 arrays of two matrixes with 4 element (2 by 2 matrix)'\n",
    "    assert len(mu_s.flatten()) == len(mu_s) * 2 * 2, 'Error! mean for each class was not entered!\\nmu_s must be an array of six elements each element of contains a vector by size of 2*1!'\n",
    "\n",
    "\n",
    "    ds_results = pd.DataFrame(columns=[ 'dataset', 'TP', 'TN', 'FP', 'FN', 'accuracy'])\n",
    "    \n",
    "    ## iterate over each dataset\n",
    "    for i in range(0, len(datasets_name)):\n",
    "\n",
    "        ## to save each label\n",
    "        classified_labels = []\n",
    "        ## read dataset\n",
    "        dataset = pd.read_csv(datasets_name[i])\n",
    "        \n",
    "        ## iterate to get each row in dataset\n",
    "        for j in range(0, len(dataset)):\n",
    "            \n",
    "            ## get each feature for each row\n",
    "            x1 = ds_A['feature_one'].iloc[j]\n",
    "            x2 = ds_A['feature_two'].iloc[j]\n",
    "\n",
    "            ## calculate the probability for calss 1\n",
    "            p_class1 = guassian_multivariate(mu_s[i][0], Sigma_s[i][0], x1, x2)\n",
    "\n",
    "            ## calculate the probability for calss 2\n",
    "            p_class2 = guassian_multivariate(mu_s[i][1], Sigma_s[i][1], x1, x2)\n",
    "\n",
    "            ## class 2 has the label 1 (True)\n",
    "            ## class 1 has the label 0 (False)\n",
    "            label = p_class2 > p_class1\n",
    "\n",
    "            classified_labels.append(label)\n",
    "        \n",
    "        ## result of one of the datasets\n",
    "        ds_partial_result = pd.DataFrame()\n",
    "        ds_partial_result = check_confusion_matrix(classified_labels, dataset.label)\n",
    "        ds_partial_result['dataset'] = datasets_name[i][-10:]\n",
    "\n",
    "        ds_results = ds_results.append(ds_partial_result, ignore_index=True)\n",
    "\n",
    "    return ds_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the mean vectors array for each dataset A, B, C, D, E, F\n",
    "mu_s = np.array([[[0,0], [2, 2]], \n",
    "            [[0,0], [0,0]], \n",
    "            [[0,0], [0,0]],\n",
    "            [[0,0], [0,0]], \n",
    "            [[0,0], [-0.8,0.8]],\n",
    "            [[0,0], [1,6]]])\n",
    "\n",
    "## create the covariance matrix array for each dataset A, B, C, D, E, F\n",
    "## each class have different covariance\n",
    "Sigma_A1 = np.matrix('1 -0.8; -0.8 1')\n",
    "Sigma_A2 = np.matrix('1 0.8; 0.8 1')\n",
    "\n",
    "Sigma_B1 = np.matrix('1 -0.75; -0.75 1')\n",
    "Sigma_B2 = np.matrix('1 0.75; 0.75 1')\n",
    "\n",
    "Sigma_C1 = np.matrix('1.75 0; 0 0.25')\n",
    "Sigma_C2 = np.matrix('0.25 0; 0 1.75')\n",
    "\n",
    "Sigma_D1 = np.matrix('1 0; 0 1')\n",
    "Sigma_D2 = np.matrix('9 0; 0 9')\n",
    "\n",
    "Sigma_E1 = np.matrix('3 1; 1 0.5')\n",
    "Sigma_E2 = np.matrix('3 1; 1 0.5')\n",
    "\n",
    "Sigma_F1 = np.matrix('3 1; 1 0.5')\n",
    "Sigma_F2 = np.matrix('3 1; 1 0.5')\n",
    "\n",
    "## appand all into an array\n",
    "Sigma_s = np.array([[Sigma_A1, Sigma_A2],\n",
    "                    [Sigma_B1, Sigma_B2],\n",
    "                    [Sigma_C1, Sigma_C2],\n",
    "                    [Sigma_D1, Sigma_D2],\n",
    "                    [Sigma_E1, Sigma_E2],\n",
    "                    [Sigma_F1, Sigma_F2] ])\n",
    "\n",
    "dataset_names = []\n",
    "for char in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "    dataset_names.append(f\"../processed_dataset/{char}train.csv\")\n",
    "\n",
    "result_ds = bayes_classifier(dataset_names, mu_s, Sigma_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atrain.csv</td>\n",
       "      <td>975</td>\n",
       "      <td>815</td>\n",
       "      <td>185</td>\n",
       "      <td>25</td>\n",
       "      <td>89.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Btrain.csv</td>\n",
       "      <td>964</td>\n",
       "      <td>799</td>\n",
       "      <td>201</td>\n",
       "      <td>36</td>\n",
       "      <td>88.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ctrain.csv</td>\n",
       "      <td>497</td>\n",
       "      <td>520</td>\n",
       "      <td>480</td>\n",
       "      <td>503</td>\n",
       "      <td>50.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dtrain.csv</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etrain.csv</td>\n",
       "      <td>948</td>\n",
       "      <td>492</td>\n",
       "      <td>508</td>\n",
       "      <td>52</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ftrain.csv</td>\n",
       "      <td>955</td>\n",
       "      <td>492</td>\n",
       "      <td>508</td>\n",
       "      <td>45</td>\n",
       "      <td>72.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset    TP   TN    FP   FN  accuracy\n",
       "0  Atrain.csv   975  815   185   25     89.50\n",
       "1  Btrain.csv   964  799   201   36     88.15\n",
       "2  Ctrain.csv   497  520   480  503     50.85\n",
       "3  Dtrain.csv  1000    0  1000    0     50.00\n",
       "4  Etrain.csv   948  492   508   52     72.00\n",
       "5  Ftrain.csv   955  492   508   45     72.35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "Now we tested our bayes classifier and saw that it can be a classifier since we know our distribution parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
