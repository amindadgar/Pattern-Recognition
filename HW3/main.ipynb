{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486ce235-07e6-4889-9f8f-f2638da39ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19188e9-fb26-4e22-b79a-3b988eed7bbb",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288764d8-0f42-48b6-843f-ef8bd20d21c1",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c16a9-743c-43e9-87d6-47af4d38ea0e",
   "metadata": {},
   "source": [
    "In this section we will go through the data \n",
    "Reading the data and some preprations\n",
    "<br>\n",
    "\n",
    "The training contains float data but they are in string format so we must split them\n",
    "delimiter is space and the first character is space, So we will go through string data and convert it to float \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adba8e54-2e7f-4647-87b3-12953dbe5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### read dataset ####################\n",
    "def process_string_dataset(string_data, delimiter = ' '):\n",
    "    \"\"\"\n",
    "    convert the data we have in string to float\n",
    "    string_data can be lines of strings\n",
    "    \"\"\"\n",
    "    ## count of data lines\n",
    "    data_line_count = len(string_data)\n",
    "\n",
    "    ## Data is our data values in float\n",
    "    data_floats = []\n",
    "    ## create a temp string to save each numbers character\n",
    "    temp_string = ''\n",
    "\n",
    "    ## go through the data and convert it to float\n",
    "    for index in range(0, data_line_count):\n",
    "        data_floats.append([])\n",
    "        for character in string_data[index][1:]:\n",
    "            if(character != delimiter and character != '\\n'):\n",
    "                temp_string += character\n",
    "            else:\n",
    "                ## if the string goes to delimiter convert the data into float\n",
    "                ## and reset temp_string variable to save the next data\n",
    "                data_floats[index].append(float(temp_string))\n",
    "                temp_string = ''\n",
    "                \n",
    "    return data_floats\n",
    "\n",
    "\n",
    "\n",
    "def read_dataset(name):\n",
    "    \"\"\"\n",
    "    read our given dataset and return the datas\n",
    "    name is the dataset directory with its name can be forexample: ../toy/Atrain\n",
    "    \"\"\"\n",
    "    file = open(name, 'r')\n",
    "\n",
    "    lines = file.readlines()\n",
    "    data_lines = []\n",
    "    for line in lines:\n",
    "        ## dataset with # in the start does not contain data\n",
    "        if(line[0] != '#'):\n",
    "            data_lines.append(line)\n",
    "            \n",
    "    ## convert to float and return the ready dataset\n",
    "    float_data = process_string_dataset(data_lines)\n",
    "    return float_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221b9ed5-0aa6-4e22-85dc-302a788ff503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data = read_dataset('toy dataset/Atrain')\n",
    "np.array(train_raw_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7ce47-cb12-4226-96f6-766eaf1640be",
   "metadata": {},
   "source": [
    "since the data was 2*1000 (For each class) we create two matrixes <br>\n",
    "two matrixes was made and the two shows the 2 classes we have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0ec5a6-3d25-45ac-9107-37cd082b6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the claases matrix as in file\n",
    "train_class1 = np.matrix(train_raw_data[:2])\n",
    "train_class2 = np.matrix(train_raw_data[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43c9a1-4a22-4855-b59c-200b60aa16f5",
   "metadata": {},
   "source": [
    "Convert Dataset into pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e0b15a-3ba9-48a8-8b88-5dcb6421f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_classes(data_frames, labels):\n",
    "    \"\"\"\n",
    "    Consider each dataframe a class of our data\n",
    "    attach the dataframes into one and add the class lebels\n",
    "    Inputs:\n",
    "    data_frames is an array of data_frames\n",
    "    lebels is the labels to the classes\n",
    "    \"\"\"\n",
    "    \n",
    "    data_frame_count = len(data_frames)\n",
    "    \n",
    "    ## create an empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0, data_frame_count):\n",
    "        ## create the label array for each class with the class data count\n",
    "        class_label = np.full(len(data_frames[i]), labels[i])\n",
    "        ## add the label to each class\n",
    "        data_frames[i]['label'] = class_label \n",
    "        df = df.append(data_frames[i], ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "## convert each class to a dataframe\n",
    "def convert_to_pd_dataframe(matrix_data):\n",
    "    \"\"\"\n",
    "    convert a dataset in the form of matrix into pandas dataframe\n",
    "    Inputs:\n",
    "    matrix_data with two feature space\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(matrix_data, columns=['feature_one', 'feature_two']) \n",
    "    \n",
    "    return df\n",
    "def convert_rowData_df(row_Datas, labels):\n",
    "    \"\"\"\n",
    "    convert raw data into dataframes\n",
    "    Input:\n",
    "    row_Datas must be an array with the raw datas,\n",
    "    if we had one raw data then it must be as [raw_data]\n",
    "    each raw_data is for one class\n",
    "    \n",
    "    lebels is the labels to the data classes\n",
    "    \"\"\"\n",
    "    ## create an array containing the dataframes \n",
    "    df_class_arrays = []\n",
    "    \n",
    "    ## get the count of row datas needed to be converted\n",
    "    count = len(row_Datas)\n",
    "    \n",
    "    ## go through each row data array and create get a dataframe for each\n",
    "    for i in range(0, count):\n",
    "        df = convert_to_pd_dataframe(np.matrix(row_Datas[i]))\n",
    "        df_class_arrays.append(df)\n",
    "    \n",
    "    ## attach the dataframes of each row data (each row data represent a class)\n",
    "    df = attach_classes(df_class_arrays, labels)\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5953add5-ac7a-43bb-9f8a-0b33081018de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_one</th>\n",
       "      <th>feature_two</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.813596</td>\n",
       "      <td>1.423864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347811</td>\n",
       "      <td>-0.494301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188346</td>\n",
       "      <td>-0.277319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167306</td>\n",
       "      <td>0.179168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.899921</td>\n",
       "      <td>1.323836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_one  feature_two  label\n",
       "0    -0.813596     1.423864      0\n",
       "1    -0.347811    -0.494301      0\n",
       "2     0.188346    -0.277319      0\n",
       "3     0.167306     0.179168      0\n",
       "4    -0.899921     1.323836      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = convert_rowData_df([train_class1.T, train_class2.T], [0, 1])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84598da-58de-4509-ad31-1272e8f0d4e8",
   "metadata": {},
   "source": [
    "### implementing KNN algorithm\n",
    "As we know about the algorithm it uses the k nearest neigber to check which class it belongs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7adc0d-0b6c-4b4d-bfe9-4ade0811bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the k value\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7459f64f-699a-4ecf-bf16-a516b227c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test dataset\n",
    "test_raw_data = read_dataset('toy dataset/Atest')\n",
    "## get classes and convert to matrix representation\n",
    "test_raw_class1 = np.array(test_raw_data).T[1000:]\n",
    "test_raw_class1 = np.matrix(test_raw_class1)\n",
    "\n",
    "test_raw_class2 = np.array(test_raw_data).T[:1000]\n",
    "test_raw_class2 = np.matrix(test_raw_class2)\n",
    "\n",
    "df_test = convert_rowData_df([test_raw_class1, test_raw_class2], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b802913-b979-4789-9beb-38e15c7b9a8f",
   "metadata": {},
   "source": [
    "To calculate the Euclidean distance we use the formula below\n",
    "$$\n",
    "\\begin{equation}\n",
    "    d = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "And our dataset has just two feature and then we can expand the above formula to use as below ( For each class we have to calculate the formula) \n",
    "$$\n",
    "\\begin{equation}\n",
    "d = \\sqrt{(feature\\_one_{test} - feature\\_one_{class1})^2 + (feature\\_two_{test} - feature\\_two_{class1})^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "d = \\sqrt{(feature\\_one_{test} - feature\\_one_{class2})^2 + (feature\\_two_{test} - feature\\_two_{class2})^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "*Note:* the equations needed to be calculated for each point. <br>\n",
    "*Note 2:* The Pythagorean theorem is the more generalized of the equation in above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff404652-1e34-4c3b-a823-af20409beb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is same as above\n",
    "\n",
    "## this variable is made to save the result of distances\n",
    "distances = []\n",
    "\n",
    "## start the test phase\n",
    "for i in range(0, 2000):\n",
    "    d = (df_train['feature_one'] - df_test.iloc[i]['feature_one']) ** 2\n",
    "    d += (df_train['feature_two']- df_test.iloc[i]['feature_two']) ** 2\n",
    "    \n",
    "    d = np.sqrt(d)\n",
    "    distances.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a21190-35f2-4889-96f4-1cf5f8420e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_votes = []\n",
    "for i in range(0,2000):\n",
    "    ## get the nearest K points\n",
    "    d = distances[i].sort_values()[:K]\n",
    "    nearest_indexes = d.index\n",
    "    \n",
    "    labels = df_train.iloc[nearest_indexes].label\n",
    "    \n",
    "    ## use the mean to calculate the average vote\n",
    "    vote = labels.mean()\n",
    "    \n",
    "    test_label_votes.append(vote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a563c56-6ea7-41c7-bdfb-f26e8a2edd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the threshold that uses to classify test data\n",
    "THRESHOLD = 0.5\n",
    "test_labels = np.array(test_label_votes) > 0.5\n",
    "test_labels = [1 if label else 0 for label in test_labels]\n",
    "classify = (test_labels == df_test.label).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e20b0e5a-b5e2-485f-901e-382c6884468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e8910-95be-465e-b58d-e921b4cda58c",
   "metadata": {},
   "source": [
    "we can see that 107 of test data are correctly classified with $K = 5$ <br>\n",
    "Now we will capsulate the calculations in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8aba5962-be31-4efd-9e4e-c99c7d23f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_data(data, test_data ,THRESHOLD):\n",
    "    \"\"\"\n",
    "    Reform an array of floats between one and zero with the threshold value into integers as 0 and 1\n",
    "    Inputs:\n",
    "    THRESHOLD is the value to set the data whether into 0 or 1 \n",
    "    data is the float array\n",
    "    \"\"\"\n",
    "    test_labels = np.array(data) >= 0.5\n",
    "    test_labels = [1 if label else 0 for label in test_labels]\n",
    "    classify = (test_labels == test_data.label).values\n",
    "    \n",
    "    return classify\n",
    "\n",
    "def KNN(K, train_data, test_data, features, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    The K nearest neighbor algorithm\n",
    "    \n",
    "    Inputs:\n",
    "    K is the KNN algorithm parameter (a positive integer value)\n",
    "    train_data and test_data in the format of pandas dataframe, the algorithm's food!\n",
    "    features are the feature for each data\n",
    "    threshold is the value to decide the result of KNN algorithm\n",
    "    \"\"\"\n",
    "        \n",
    "    ## get the algorithm start time\n",
    "    start_time = time.time_ns()\n",
    "    \n",
    "    assert K > 0, 'K must be a positive value and also not zero!'\n",
    "\n",
    "    test_label_votes = []\n",
    "    \n",
    "    ## start the test phase\n",
    "    for index in range(0, len(test_data)):\n",
    "        \n",
    "        d = 0\n",
    "        for feature in features:\n",
    "            d += (train_data[feature]- test_data.iloc[index][feature]) ** 2\n",
    "        d = np.sqrt(d)\n",
    "\n",
    "        ## the index of K nearest neighbor points\n",
    "        nearest_indexes = d.sort_values()[:K].index\n",
    "                \n",
    "        ## get the labels of nearest data\n",
    "        labels = train_data.iloc[nearest_indexes].label\n",
    "        \n",
    "        ## use the mean to calculate the average vote\n",
    "        vote = labels.mean()\n",
    "        test_label_votes.append(vote)\n",
    "        \n",
    "    ## decide the voting process in KNN\n",
    "    classified_data = reform_data(test_label_votes, test_data, threshold)\n",
    "\n",
    "    finish_time = time.time_ns()\n",
    "    print('Finished! algorithm time: ', ((finish_time - start_time) / 1000), ' miliseconds')\n",
    "        \n",
    "    return classified_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad78343-78a3-4c82-a42d-cab3fba2678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(df_test.columns[df_test.columns != 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8d9a1-4d7c-487f-897f-c1d17fe75702",
   "metadata": {},
   "source": [
    "check the memory and time usage of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd4b4c97-93d5-4ec7-a3d0-b22e65524c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! algorithm time:  2107474.459  miliseconds\n",
      "peak memory: 149.11 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit test_labels = KNN(5 , df_train, df_test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c794a3-695a-4899-bdad-f64dfbdcbd31",
   "metadata": {},
   "source": [
    "As you can see the increment was about 0 mega Bytes, This means that it does not really consume alot of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3f767a7-30af-45d1-a0f9-f18016ef07c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc09a9-1b41-41e3-9593-cd0e4340ed70",
   "metadata": {},
   "source": [
    "#### Now its time to check different K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dcc8259-ed61-4556-9f48-62ee634e8a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! algorithm time:  2160221.174  miliseconds\n",
      "Finished! algorithm time:  2126278.027  miliseconds\n",
      "Finished! algorithm time:  2140965.288  miliseconds\n",
      "Finished! algorithm time:  2090854.29  miliseconds\n",
      "Finished! algorithm time:  2080330.263  miliseconds\n",
      "Finished! algorithm time:  2075208.019  miliseconds\n",
      "Finished! algorithm time:  2089939.41  miliseconds\n",
      "Finished! algorithm time:  2074039.985  miliseconds\n",
      "Finished! algorithm time:  2084358.741  miliseconds\n",
      "Finished! algorithm time:  2093722.499  miliseconds\n"
     ]
    }
   ],
   "source": [
    "## remove the target feature\n",
    "features = np.array(df_test.columns[df_test.columns != 'label'])\n",
    "\n",
    "## save the result of different K values\n",
    "labels_classified = {}\n",
    "for K in [1, 2, 5, 10, 15, 20, 50, 100, 500, 1000]:\n",
    "    label = KNN(K, df_train, df_test, features)\n",
    "    labels_classified[str(K)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adad0a49-1572-4284-a047-dec453a02bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1  True classified 153 \taccuracy: 7.650000\n",
      "K=2  True classified 186 \taccuracy: 9.300000\n",
      "K=5  True classified 107 \taccuracy: 5.350000\n",
      "K=10  True classified 91 \taccuracy: 4.550000\n",
      "K=15  True classified 90 \taccuracy: 4.500000\n",
      "K=20  True classified 91 \taccuracy: 4.550000\n",
      "K=50  True classified 92 \taccuracy: 4.600000\n",
      "K=100  True classified 94 \taccuracy: 4.700000\n",
      "K=500  True classified 104 \taccuracy: 5.200000\n",
      "K=1000  True classified 123 \taccuracy: 6.150000\n"
     ]
    }
   ],
   "source": [
    "for key, item in labels_classified.items():\n",
    "    print('K=%s ' % key, 'True classified %s' % item.sum(), '\\taccuracy: %f' % (item.sum()*100 / len(item)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df0dcd-af36-4e44-addd-0b07367a5144",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c332a40-5d49-4084-875a-f5740afa5cbf",
   "metadata": {},
   "source": [
    "Use the *Itrain* dataset <br>\n",
    "split it for into 100 for validation set and 900 for training  <br>\n",
    "*NOTE: we have processed the data into csv format using convert_to_csv.py script and saved them into processed_dataset directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15b30643-8c28-4364-b347-e0778cb19c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! algorithm time:  414542.223  miliseconds\n",
      "K=1  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  404241.222  miliseconds\n",
      "K=2  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  403420.411  miliseconds\n",
      "K=3  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  402239.077  miliseconds\n",
      "K=5  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  403473.398  miliseconds\n",
      "K=7  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  403851.638  miliseconds\n",
      "K=9  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  401086.326  miliseconds\n",
      "K=10  True classified count 200 from 200 \taccuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "Itrain_df = pd.read_csv('processed_dataset/Itrain.csv')\n",
    "\n",
    "features = Itrain_df.columns[Itrain_df.columns != 'label']\n",
    "\n",
    "history = {}\n",
    "for K in [1, 2, 3, 5, 7, 9, 10]:\n",
    "    ## use 900 of each class for training    \n",
    "    df_training = Itrain_df[Itrain_df.label == 0][:900]\n",
    "    df_training = df_training.append(Itrain_df[Itrain_df.label == 1][:900])\n",
    "    \n",
    "    ## now we have a dataframe with 1800 values but the indexes are not set properly\n",
    "    ## Since we are directly working with index in our algorithm, we need to reset it\n",
    "    df_training = df_training.reset_index(drop=True)\n",
    "\n",
    "    ## use 100 of each class for validation\n",
    "    df_validation = Itrain_df[Itrain_df.label == 0][900:]\n",
    "    df_validation = df_validation.append(Itrain_df[Itrain_df.label == 1][900:])\n",
    "    \n",
    "    ## now we have a dataframe with 200 values but the indexes are not set properly\n",
    "    ## Since we are directly working with index in our algorithm, we need to reset it\n",
    "    df_validation = df_validation.reset_index(drop=True)\n",
    "    \n",
    "    label = KNN(K, df_training, df_validation, features)\n",
    "    \n",
    "    print('K=%s ' % K, 'True classified count %s from %s' % (label.sum(), len(label)), '\\taccuracy: %f' % (label.sum()*100 / len(label)))    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
