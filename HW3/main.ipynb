{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486ce235-07e6-4889-9f8f-f2638da39ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19188e9-fb26-4e22-b79a-3b988eed7bbb",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288764d8-0f42-48b6-843f-ef8bd20d21c1",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c16a9-743c-43e9-87d6-47af4d38ea0e",
   "metadata": {},
   "source": [
    "In this section we will go through the data \n",
    "Reading the data and some preprations\n",
    "<br>\n",
    "\n",
    "The training contains float data but they are in string format so we must split them\n",
    "delimiter is space and the first character is space, So we will go through string data and convert it to float \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adba8e54-2e7f-4647-87b3-12953dbe5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### read dataset ####################\n",
    "def process_string_dataset(string_data, delimiter = ' '):\n",
    "    \"\"\"\n",
    "    convert the data we have in string to float\n",
    "    string_data can be lines of strings\n",
    "    \"\"\"\n",
    "    ## count of data lines\n",
    "    data_line_count = len(string_data)\n",
    "\n",
    "    ## Data is our data values in float\n",
    "    data_floats = []\n",
    "    ## create a temp string to save each numbers character\n",
    "    temp_string = ''\n",
    "\n",
    "    ## go through the data and convert it to float\n",
    "    for index in range(0, data_line_count):\n",
    "        data_floats.append([])\n",
    "        for character in string_data[index][1:]:\n",
    "            if(character != delimiter and character != '\\n'):\n",
    "                temp_string += character\n",
    "            else:\n",
    "                ## if the string goes to delimiter convert the data into float\n",
    "                ## and reset temp_string variable to save the next data\n",
    "                data_floats[index].append(float(temp_string))\n",
    "                temp_string = ''\n",
    "                \n",
    "    return data_floats\n",
    "\n",
    "\n",
    "\n",
    "def read_dataset(name):\n",
    "    \"\"\"\n",
    "    read our given dataset and return the datas\n",
    "    name is the dataset directory with its name can be forexample: ../toy/Atrain\n",
    "    \"\"\"\n",
    "    file = open(name, 'r')\n",
    "\n",
    "    lines = file.readlines()\n",
    "    data_lines = []\n",
    "    for line in lines:\n",
    "        ## dataset with # in the start does not contain data\n",
    "        if(line[0] != '#'):\n",
    "            data_lines.append(line)\n",
    "            \n",
    "    ## convert to float and return the ready dataset\n",
    "    float_data = process_string_dataset(data_lines)\n",
    "    return float_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221b9ed5-0aa6-4e22-85dc-302a788ff503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_data = read_dataset('toy dataset/Atrain')\n",
    "np.array(train_raw_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7ce47-cb12-4226-96f6-766eaf1640be",
   "metadata": {},
   "source": [
    "since the data was 2*1000 (For each class) we create two matrixes <br>\n",
    "two matrixes was made and the two shows the 2 classes we have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0ec5a6-3d25-45ac-9107-37cd082b6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the claases matrix as in file\n",
    "train_class1 = np.matrix(train_raw_data[:2])\n",
    "train_class2 = np.matrix(train_raw_data[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43c9a1-4a22-4855-b59c-200b60aa16f5",
   "metadata": {},
   "source": [
    "Convert Dataset into pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5e0b15a-3ba9-48a8-8b88-5dcb6421f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_classes(data_frames, labels):\n",
    "    \"\"\"\n",
    "    Consider each dataframe a class of our data\n",
    "    attach the dataframes into one and add the class lebels\n",
    "    Inputs:\n",
    "    data_frames is an array of data_frames\n",
    "    lebels is the labels to the classes\n",
    "    \"\"\"\n",
    "    \n",
    "    data_frame_count = len(data_frames)\n",
    "    \n",
    "    ## create an empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0, data_frame_count):\n",
    "        ## create the label array for each class with the class data count\n",
    "        class_label = np.full(len(data_frames[i]), labels[i])\n",
    "        ## add the label to each class\n",
    "        data_frames[i]['label'] = class_label \n",
    "        df = df.append(data_frames[i], ignore_index=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "## convert each class to a dataframe\n",
    "def convert_to_pd_dataframe(matrix_data):\n",
    "    \"\"\"\n",
    "    convert a dataset in the form of matrix into pandas dataframe\n",
    "    Inputs:\n",
    "    matrix_data with two feature space\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(matrix_data, columns=['feature_one', 'feature_two']) \n",
    "    \n",
    "    return df\n",
    "def convert_rowData_df(row_Datas, labels):\n",
    "    \"\"\"\n",
    "    convert raw data into dataframes\n",
    "    Input:\n",
    "    row_Datas must be an array with the raw datas,\n",
    "    if we had one raw data then it must be as [raw_data]\n",
    "    each raw_data is for one class\n",
    "    \n",
    "    lebels is the labels to the data classes\n",
    "    \"\"\"\n",
    "    ## create an array containing the dataframes \n",
    "    df_class_arrays = []\n",
    "    \n",
    "    ## get the count of row datas needed to be converted\n",
    "    count = len(row_Datas)\n",
    "    \n",
    "    ## go through each row data array and create get a dataframe for each\n",
    "    for i in range(0, count):\n",
    "        df = convert_to_pd_dataframe(np.matrix(row_Datas[i]))\n",
    "        df_class_arrays.append(df)\n",
    "    \n",
    "    ## attach the dataframes of each row data (each row data represent a class)\n",
    "    df = attach_classes(df_class_arrays, labels)\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5953add5-ac7a-43bb-9f8a-0b33081018de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_one</th>\n",
       "      <th>feature_two</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.813596</td>\n",
       "      <td>1.423864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347811</td>\n",
       "      <td>-0.494301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188346</td>\n",
       "      <td>-0.277319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167306</td>\n",
       "      <td>0.179168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.899921</td>\n",
       "      <td>1.323836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_one  feature_two  label\n",
       "0    -0.813596     1.423864      0\n",
       "1    -0.347811    -0.494301      0\n",
       "2     0.188346    -0.277319      0\n",
       "3     0.167306     0.179168      0\n",
       "4    -0.899921     1.323836      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = convert_rowData_df([train_class1.T, train_class2.T], [0, 1])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84598da-58de-4509-ad31-1272e8f0d4e8",
   "metadata": {},
   "source": [
    "### implementing KNN algorithm\n",
    "As we know about the algorithm it uses the k nearest neigber to check which class it belongs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e7adc0d-0b6c-4b4d-bfe9-4ade0811bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the k value\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7459f64f-699a-4ecf-bf16-a516b227c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test dataset\n",
    "test_raw_data = read_dataset('toy dataset/Atest')\n",
    "## get classes and convert to matrix representation\n",
    "test_raw_class1 = np.array(test_raw_data).T[1000:]\n",
    "test_raw_class1 = np.matrix(test_raw_class1)\n",
    "\n",
    "test_raw_class2 = np.array(test_raw_data).T[:1000]\n",
    "test_raw_class2 = np.matrix(test_raw_class2)\n",
    "\n",
    "df_test = convert_rowData_df([test_raw_class1, test_raw_class2], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b802913-b979-4789-9beb-38e15c7b9a8f",
   "metadata": {},
   "source": [
    "To calculate the Euclidean distance we use the formula below\n",
    "$$\n",
    "\\begin{equation}\n",
    "    d = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "And our dataset has just two feature and then we can expand the above formula to use as below ( For each class we have to calculate the formula) \n",
    "$$\n",
    "\\begin{equation}\n",
    "d = \\sqrt{(feature\\_one_{test} - feature\\_one_{class1})^2 + (feature\\_two_{test} - feature\\_two_{class1})^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "d = \\sqrt{(feature\\_one_{test} - feature\\_one_{class2})^2 + (feature\\_two_{test} - feature\\_two_{class2})^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "*Note:* the equations needed to be calculated for each point. <br>\n",
    "*Note 2:* The Pythagorean theorem is the more generalized of the equation in above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff404652-1e34-4c3b-a823-af20409beb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is same as above\n",
    "\n",
    "## this variable is made to save the result of distances\n",
    "distances = []\n",
    "\n",
    "## start the test phase\n",
    "for i in range(0, 2000):\n",
    "    d = (df_train['feature_one'] - df_test.iloc[i]['feature_one']) ** 2\n",
    "    d += (df_train['feature_two']- df_test.iloc[i]['feature_two']) ** 2\n",
    "    \n",
    "    d = np.sqrt(d)\n",
    "    distances.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a21190-35f2-4889-96f4-1cf5f8420e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_votes = []\n",
    "for i in range(0,2000):\n",
    "    ## get the nearest K points\n",
    "    d = distances[i].sort_values()[:K]\n",
    "    nearest_indexes = d.index\n",
    "    \n",
    "    labels = df_train.iloc[nearest_indexes].label\n",
    "    \n",
    "    ## use the mean to calculate the average vote\n",
    "    vote = labels.mean()\n",
    "    \n",
    "    test_label_votes.append(vote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a563c56-6ea7-41c7-bdfb-f26e8a2edd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the threshold that uses to classify test data\n",
    "THRESHOLD = 0.5\n",
    "test_labels = np.array(test_label_votes) > THRESHOLD\n",
    "test_labels = [1 if label else 0 for label in test_labels]\n",
    "# classify = (test_labels == df_test.label).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e20b0e5a-b5e2-485f-901e-382c6884468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the classifier labels with actual labels\n",
    "equal_labels = (test_labels == df_test.label)\n",
    "equal_labels.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e8910-95be-465e-b58d-e921b4cda58c",
   "metadata": {},
   "source": [
    "we can see that 107 of test data are correctly classified with $K = 5$ <br>\n",
    "Now we will capsulate the calculations in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aba5962-be31-4efd-9e4e-c99c7d23f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_data(data ,THRESHOLD):\n",
    "    \"\"\"\n",
    "    Reform an array of floats between one and zero with the threshold value into integers as 0 and 1\n",
    "    Inputs:\n",
    "    THRESHOLD is the value to set the data whether into 0 or 1 \n",
    "    data is the float array\n",
    "    \"\"\"\n",
    "    test_labels = np.array(data) >= THRESHOLD\n",
    "    \n",
    "    return test_labels\n",
    "\n",
    "############################# check labels of the classified data #############################\n",
    "def check_label(actual_labels, target_labels):\n",
    "    \"\"\"\n",
    "    check the labels of the classifier output with actual data\n",
    "    \n",
    "    Inputs:\n",
    "    actual_labels are the labels that the classifier gave us\n",
    "    target_labels are the correct labels of the data\n",
    "    \"\"\"\n",
    "    \n",
    "    ## convert to numpy arrays to compute the equality of each elemnts\n",
    "    a_labels = np.array(actual_labels)\n",
    "    t_labels = np.array(target_labels)\n",
    "    \n",
    "    ## mark as True the eqaul labels\n",
    "    equal_labels = (a_labels == t_labels)\n",
    "    \n",
    "    return equal_labels\n",
    "    \n",
    "\n",
    "def KNN(K, train_data, test_data, features, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    The K nearest neighbor algorithm\n",
    "    \n",
    "    Inputs:\n",
    "    K is the KNN algorithm parameter (a positive integer value)\n",
    "    train_data and test_data in the format of pandas dataframe, the algorithm's food!\n",
    "    features are the feature for each data\n",
    "    threshold is the value to decide the result of KNN algorithm\n",
    "    \"\"\"\n",
    "        \n",
    "    ## get the algorithm start time\n",
    "    start_time = time.time_ns()\n",
    "    \n",
    "    assert K > 0, 'K must be a positive value and also not zero!'\n",
    "\n",
    "    test_label_votes = []\n",
    "    \n",
    "    ## start the test phase\n",
    "    for index in range(0, len(test_data)):\n",
    "        \n",
    "        d = 0\n",
    "        for feature in features:\n",
    "            d += (train_data[feature]- test_data.iloc[index][feature]) ** 2\n",
    "        d = np.sqrt(d)\n",
    "\n",
    "        ## the index of K nearest neighbor points\n",
    "        nearest_indexes = d.sort_values()[:K].index\n",
    "                \n",
    "        ## get the labels of nearest data\n",
    "        labels = train_data.iloc[nearest_indexes].label\n",
    "        \n",
    "        ## use the mean to calculate the average vote\n",
    "        vote = labels.mean()\n",
    "        test_label_votes.append(vote)\n",
    "        \n",
    "    ## decide the voting process in KNN\n",
    "    classified_data = reform_data(test_label_votes, threshold)\n",
    "\n",
    "    finish_time = time.time_ns()\n",
    "    print('Finished! algorithm time: ', ((finish_time - start_time) / 1000), ' miliseconds')\n",
    "        \n",
    "    return classified_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad78343-78a3-4c82-a42d-cab3fba2678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(df_test.columns[df_test.columns != 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8d9a1-4d7c-487f-897f-c1d17fe75702",
   "metadata": {},
   "source": [
    "check the memory and time usage of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4b4c97-93d5-4ec7-a3d0-b22e65524c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! algorithm time:  2109561.173  miliseconds\n",
      "peak memory: 174.25 MiB, increment: 0.48 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit test_labels = KNN(5 , df_train, df_test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c794a3-695a-4899-bdad-f64dfbdcbd31",
   "metadata": {},
   "source": [
    "As you can see the increment was about 0 mega Bytes, This means that it does not really consume alot of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f767a7-30af-45d1-a0f9-f18016ef07c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = check_label(test_labels, df_test.label)\n",
    "result.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc09a9-1b41-41e3-9593-cd0e4340ed70",
   "metadata": {},
   "source": [
    "#### Now its time to check different K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dcc8259-ed61-4556-9f48-62ee634e8a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! algorithm time:  2172647.918  miliseconds\n",
      "Finished! algorithm time:  2058391.065  miliseconds\n",
      "Finished! algorithm time:  2026945.805  miliseconds\n",
      "Finished! algorithm time:  2090292.86  miliseconds\n",
      "Finished! algorithm time:  2039694.83  miliseconds\n",
      "Finished! algorithm time:  2038825.182  miliseconds\n",
      "Finished! algorithm time:  2042348.485  miliseconds\n",
      "Finished! algorithm time:  2065345.877  miliseconds\n",
      "Finished! algorithm time:  2127289.311  miliseconds\n",
      "Finished! algorithm time:  2073999.929  miliseconds\n"
     ]
    }
   ],
   "source": [
    "## remove the target feature\n",
    "features = np.array(df_test.columns[df_test.columns != 'label'])\n",
    "\n",
    "## save the result of different K values\n",
    "labels_classified = {}\n",
    "for K in [1, 2, 5, 10, 15, 20, 50, 100, 500, 1000]:\n",
    "    label = KNN(K, df_train, df_test, features)\n",
    "    labels_classified[str(K)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adad0a49-1572-4284-a047-dec453a02bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1  True classified 153 \taccuracy: 7.650000\n",
      "K=2  True classified 186 \taccuracy: 9.300000\n",
      "K=5  True classified 107 \taccuracy: 5.350000\n",
      "K=10  True classified 91 \taccuracy: 4.550000\n",
      "K=15  True classified 90 \taccuracy: 4.500000\n",
      "K=20  True classified 91 \taccuracy: 4.550000\n",
      "K=50  True classified 92 \taccuracy: 4.600000\n",
      "K=100  True classified 94 \taccuracy: 4.700000\n",
      "K=500  True classified 104 \taccuracy: 5.200000\n",
      "K=1000  True classified 123 \taccuracy: 6.150000\n"
     ]
    }
   ],
   "source": [
    "for key, item in labels_classified.items():\n",
    "    ## check correct classification results\n",
    "    result = check_label(item, df_test.label)\n",
    "    print('K=%s ' % key, 'True classified %s' % result.sum(), '\\taccuracy: %f' % (result.sum()*100 / len(result)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df0dcd-af36-4e44-addd-0b07367a5144",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c332a40-5d49-4084-875a-f5740afa5cbf",
   "metadata": {},
   "source": [
    "Use the *Itrain* dataset <br>\n",
    "split it for into 100 for validation set and 900 for training  <br>\n",
    "*NOTE: we have processed the data into csv format using convert_to_csv.py script and saved them into processed_dataset directory*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8711331-f529-4fc8-a16e-d1df9c99aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 convert_to_csv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15b30643-8c28-4364-b347-e0778cb19c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! algorithm time:  414542.223  miliseconds\n",
      "K=1  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  404241.222  miliseconds\n",
      "K=2  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  403420.411  miliseconds\n",
      "K=3  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  402239.077  miliseconds\n",
      "K=5  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  403473.398  miliseconds\n",
      "K=7  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  403851.638  miliseconds\n",
      "K=9  True classified count 200 from 200 \taccuracy: 100.000000\n",
      "Finished! algorithm time:  401086.326  miliseconds\n",
      "K=10  True classified count 200 from 200 \taccuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "Itrain_df = pd.read_csv('processed_dataset/Itrain.csv')\n",
    "\n",
    "features = Itrain_df.columns[Itrain_df.columns != 'label']\n",
    "\n",
    "history = {}\n",
    "for K in [1, 2, 3, 5, 7, 9, 10]:\n",
    "    ## use 900 of each class for training    \n",
    "    df_training = Itrain_df[Itrain_df.label == 0][:900]\n",
    "    df_training = df_training.append(Itrain_df[Itrain_df.label == 1][:900])\n",
    "    \n",
    "    ## now we have a dataframe with 1800 values but the indexes are not set properly\n",
    "    ## Since we are directly working with index in our algorithm, we need to reset it\n",
    "    df_training = df_training.reset_index(drop=True)\n",
    "\n",
    "    ## use 100 of each class for validation\n",
    "    df_validation = Itrain_df[Itrain_df.label == 0][900:]\n",
    "    df_validation = df_validation.append(Itrain_df[Itrain_df.label == 1][900:])\n",
    "    \n",
    "    ## now we have a dataframe with 200 values but the indexes are not set properly\n",
    "    ## Since we are directly working with index in our algorithm, we need to reset it\n",
    "    df_validation = df_validation.reset_index(drop=True)\n",
    "    \n",
    "    label = KNN(K, df_training, df_validation, features)\n",
    "    \n",
    "    ## check correct classification results\n",
    "    result = check_label(label, df_validation.label)\n",
    "    \n",
    "    print('K=%s ' % K, 'True classified count %s from %s' % (result.sum(), len(result)), '\\taccuracy: %f' % (result.sum()*100 / len(result)))    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ec615-2f2d-4ac0-b002-19e7ecda8308",
   "metadata": {},
   "source": [
    "## Appendix A\n",
    "run the knn.py script just to save the outputs in the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73c106cd-34e5-4865-8eac-d36eafd89870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preforming A Dataset (ATrain.csv, ATest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  10912130.759  miliseconds\n",
      "K=1  correctly classified count: 153 \taccuracy: 7.650000\n",
      "Finished! K=2 algorithm time:  10947507.039  miliseconds\n",
      "K=2  correctly classified count: 186 \taccuracy: 9.300000\n",
      "Finished! K=5 algorithm time:  11171008.564  miliseconds\n",
      "K=5  correctly classified count: 107 \taccuracy: 5.350000\n",
      "Finished! K=10 algorithm time:  11103951.541  miliseconds\n",
      "K=10  correctly classified count: 91 \taccuracy: 4.550000\n",
      "Finished! K=15 algorithm time:  11593564.561  miliseconds\n",
      "K=15  correctly classified count: 90 \taccuracy: 4.500000\n",
      "Finished! K=20 algorithm time:  11487735.531  miliseconds\n",
      "K=20  correctly classified count: 91 \taccuracy: 4.550000\n",
      "Finished! K=50 algorithm time:  10913763.468  miliseconds\n",
      "K=50  correctly classified count: 92 \taccuracy: 4.600000\n",
      "Finished! K=100 algorithm time:  10976115.961  miliseconds\n",
      "K=100  correctly classified count: 94 \taccuracy: 4.700000\n",
      "Finished! K=500 algorithm time:  11471822.769  miliseconds\n",
      "K=500  correctly classified count: 104 \taccuracy: 5.200000\n",
      "Finished! K=1000 algorithm time:  11403722.605  miliseconds\n",
      "K=1000  correctly classified count: 123 \taccuracy: 6.150000\n",
      "\n",
      "\n",
      "\n",
      "Preforming B Dataset (BTrain.csv, BTest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  11458064.156  miliseconds\n",
      "K=1  correctly classified count: 512 \taccuracy: 25.600000\n",
      "Finished! K=2 algorithm time:  11865588.793  miliseconds\n",
      "K=2  correctly classified count: 526 \taccuracy: 26.300000\n",
      "Finished! K=5 algorithm time:  11602497.075  miliseconds\n",
      "K=5  correctly classified count: 446 \taccuracy: 22.300000\n",
      "Finished! K=10 algorithm time:  11908455.639  miliseconds\n",
      "K=10  correctly classified count: 426 \taccuracy: 21.300000\n",
      "Finished! K=15 algorithm time:  11359091.076  miliseconds\n",
      "K=15  correctly classified count: 413 \taccuracy: 20.650000\n",
      "Finished! K=20 algorithm time:  11081876.903  miliseconds\n",
      "K=20  correctly classified count: 410 \taccuracy: 20.500000\n",
      "Finished! K=50 algorithm time:  11229958.432  miliseconds\n",
      "K=50  correctly classified count: 417 \taccuracy: 20.850000\n",
      "Finished! K=100 algorithm time:  11603967.66  miliseconds\n",
      "K=100  correctly classified count: 417 \taccuracy: 20.850000\n",
      "Finished! K=500 algorithm time:  11420571.082  miliseconds\n",
      "K=500  correctly classified count: 405 \taccuracy: 20.250000\n",
      "Finished! K=1000 algorithm time:  11429949.599  miliseconds\n",
      "K=1000  correctly classified count: 409 \taccuracy: 20.450000\n",
      "\n",
      "\n",
      "\n",
      "Preforming C Dataset (CTrain.csv, CTest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  11407375.815  miliseconds\n",
      "K=1  correctly classified count: 490 \taccuracy: 24.500000\n",
      "Finished! K=2 algorithm time:  11628310.986  miliseconds\n",
      "K=2  correctly classified count: 490 \taccuracy: 24.500000\n",
      "Finished! K=5 algorithm time:  11278886.915  miliseconds\n",
      "K=5  correctly classified count: 444 \taccuracy: 22.200000\n",
      "Finished! K=10 algorithm time:  11349442.621  miliseconds\n",
      "K=10  correctly classified count: 427 \taccuracy: 21.350000\n",
      "Finished! K=15 algorithm time:  11172477.356  miliseconds\n",
      "K=15  correctly classified count: 436 \taccuracy: 21.800000\n",
      "Finished! K=20 algorithm time:  10809424.538  miliseconds\n",
      "K=20  correctly classified count: 425 \taccuracy: 21.250000\n",
      "Finished! K=50 algorithm time:  10676711.27  miliseconds\n",
      "K=50  correctly classified count: 398 \taccuracy: 19.900000\n",
      "Finished! K=100 algorithm time:  10371134.998  miliseconds\n",
      "K=100  correctly classified count: 399 \taccuracy: 19.950000\n",
      "Finished! K=500 algorithm time:  10329572.302  miliseconds\n",
      "K=500  correctly classified count: 411 \taccuracy: 20.550000\n",
      "Finished! K=1000 algorithm time:  10321984.871  miliseconds\n",
      "K=1000  correctly classified count: 430 \taccuracy: 21.500000\n",
      "\n",
      "\n",
      "\n",
      "Preforming D Dataset (DTrain.csv, DTest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  10382207.444  miliseconds\n",
      "K=1  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=2 algorithm time:  10551480.971  miliseconds\n",
      "K=2  correctly classified count: 218 \taccuracy: 10.900000\n",
      "Finished! K=5 algorithm time:  10530166.879  miliseconds\n",
      "K=5  correctly classified count: 244 \taccuracy: 12.200000\n",
      "Finished! K=10 algorithm time:  10543004.468  miliseconds\n",
      "K=10  correctly classified count: 262 \taccuracy: 13.100000\n",
      "Finished! K=15 algorithm time:  10429351.494  miliseconds\n",
      "K=15  correctly classified count: 268 \taccuracy: 13.400000\n",
      "Finished! K=20 algorithm time:  10428039.067  miliseconds\n",
      "K=20  correctly classified count: 267 \taccuracy: 13.350000\n",
      "Finished! K=50 algorithm time:  10440337.017  miliseconds\n",
      "K=50  correctly classified count: 283 \taccuracy: 14.150000\n",
      "Finished! K=100 algorithm time:  10706189.876  miliseconds\n",
      "K=100  correctly classified count: 310 \taccuracy: 15.500000\n",
      "Finished! K=500 algorithm time:  10988758.677  miliseconds\n",
      "K=500  correctly classified count: 540 \taccuracy: 27.000000\n",
      "Finished! K=1000 algorithm time:  10776258.839  miliseconds\n",
      "K=1000  correctly classified count: 1000 \taccuracy: 50.000000\n",
      "\n",
      "\n",
      "\n",
      "Preforming E Dataset (ETrain.csv, ETest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  10539206.922  miliseconds\n",
      "K=1  correctly classified count: 243 \taccuracy: 12.150000\n",
      "Finished! K=2 algorithm time:  10519386.284  miliseconds\n",
      "K=2  correctly classified count: 248 \taccuracy: 12.400000\n",
      "Finished! K=5 algorithm time:  10496333.069  miliseconds\n",
      "K=5  correctly classified count: 196 \taccuracy: 9.800000\n",
      "Finished! K=10 algorithm time:  10455990.653  miliseconds\n",
      "K=10  correctly classified count: 197 \taccuracy: 9.850000\n",
      "Finished! K=15 algorithm time:  10487326.012  miliseconds\n",
      "K=15  correctly classified count: 192 \taccuracy: 9.600000\n",
      "Finished! K=20 algorithm time:  10458758.748  miliseconds\n",
      "K=20  correctly classified count: 192 \taccuracy: 9.600000\n",
      "Finished! K=50 algorithm time:  10507733.516  miliseconds\n",
      "K=50  correctly classified count: 180 \taccuracy: 9.000000\n",
      "Finished! K=100 algorithm time:  10901389.634  miliseconds\n",
      "K=100  correctly classified count: 176 \taccuracy: 8.800000\n",
      "Finished! K=500 algorithm time:  11381730.136  miliseconds\n",
      "K=500  correctly classified count: 284 \taccuracy: 14.200000\n",
      "Finished! K=1000 algorithm time:  11417768.544  miliseconds\n",
      "K=1000  correctly classified count: 460 \taccuracy: 23.000000\n",
      "\n",
      "\n",
      "\n",
      "Preforming F Dataset (FTrain.csv, FTest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  11335675.286  miliseconds\n",
      "K=1  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=2 algorithm time:  11263269.859  miliseconds\n",
      "K=2  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=5 algorithm time:  11126810.174  miliseconds\n",
      "K=5  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=10 algorithm time:  11168066.777  miliseconds\n",
      "K=10  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=15 algorithm time:  10874824.884  miliseconds\n",
      "K=15  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=20 algorithm time:  10459264.383  miliseconds\n",
      "K=20  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=50 algorithm time:  10844061.477  miliseconds\n",
      "K=50  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=100 algorithm time:  11174251.928  miliseconds\n",
      "K=100  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=500 algorithm time:  11318432.845  miliseconds\n",
      "K=500  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=1000 algorithm time:  11216826.027  miliseconds\n",
      "K=1000  correctly classified count: 2 \taccuracy: 0.100000\n",
      "\n",
      "\n",
      "\n",
      "Preforming G Dataset (GTrain.csv, GTest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  11265841.422  miliseconds\n",
      "K=1  correctly classified count: 155 \taccuracy: 7.750000\n",
      "Finished! K=2 algorithm time:  11255404.716  miliseconds\n",
      "K=2  correctly classified count: 153 \taccuracy: 7.650000\n",
      "Finished! K=5 algorithm time:  11176660.557  miliseconds\n",
      "K=5  correctly classified count: 110 \taccuracy: 5.500000\n",
      "Finished! K=10 algorithm time:  11265780.38  miliseconds\n",
      "K=10  correctly classified count: 100 \taccuracy: 5.000000\n",
      "Finished! K=15 algorithm time:  10398907.711  miliseconds\n",
      "K=15  correctly classified count: 93 \taccuracy: 4.650000\n",
      "Finished! K=20 algorithm time:  10905258.872  miliseconds\n",
      "K=20  correctly classified count: 94 \taccuracy: 4.700000\n",
      "Finished! K=50 algorithm time:  10731660.191  miliseconds\n",
      "K=50  correctly classified count: 88 \taccuracy: 4.400000\n",
      "Finished! K=100 algorithm time:  11064479.808  miliseconds\n",
      "K=100  correctly classified count: 84 \taccuracy: 4.200000\n",
      "Finished! K=500 algorithm time:  11555326.994  miliseconds\n",
      "K=500  correctly classified count: 83 \taccuracy: 4.150000\n",
      "Finished! K=1000 algorithm time:  10862363.09  miliseconds\n",
      "K=1000  correctly classified count: 90 \taccuracy: 4.500000\n",
      "\n",
      "\n",
      "\n",
      "Preforming H Dataset (HTrain.csv, HTest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  10943491.349  miliseconds\n",
      "K=1  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=2 algorithm time:  10969474.961  miliseconds\n",
      "K=2  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=5 algorithm time:  10777678.51  miliseconds\n",
      "K=5  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=10 algorithm time:  10905098.328  miliseconds\n",
      "K=10  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=15 algorithm time:  10729937.402  miliseconds\n",
      "K=15  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=20 algorithm time:  10406612.217  miliseconds\n",
      "K=20  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=50 algorithm time:  10424303.398  miliseconds\n",
      "K=50  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=100 algorithm time:  10409662.487  miliseconds\n",
      "K=100  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=500 algorithm time:  10541464.411  miliseconds\n",
      "K=500  correctly classified count: 1 \taccuracy: 0.050050\n",
      "Finished! K=1000 algorithm time:  10496210.582  miliseconds\n",
      "K=1000  correctly classified count: 1997 \taccuracy: 99.949950\n",
      "\n",
      "\n",
      "\n",
      "Preforming I Dataset (ITrain.csv, ITest.csv)\n",
      "-----------------------------------------------\n",
      "Finished! K=1 algorithm time:  10426727.006  miliseconds\n",
      "K=1  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=2 algorithm time:  10695393.394  miliseconds\n",
      "K=2  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=5 algorithm time:  10888712.802  miliseconds\n",
      "K=5  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=10 algorithm time:  10805802.45  miliseconds\n",
      "K=10  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=15 algorithm time:  10906272.527  miliseconds\n",
      "K=15  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=20 algorithm time:  10641493.078  miliseconds\n",
      "K=20  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=50 algorithm time:  10672971.62  miliseconds\n",
      "K=50  correctly classified count: 0 \taccuracy: 0.000000\n",
      "Finished! K=100 algorithm time:  10620820.661  miliseconds\n",
      "K=100  correctly classified count: 1 \taccuracy: 0.050000\n",
      "Finished! K=500 algorithm time:  10680725.877  miliseconds\n",
      "K=500  correctly classified count: 114 \taccuracy: 5.700000\n",
      "Finished! K=1000 algorithm time:  11145807.55  miliseconds\n",
      "K=1000  correctly classified count: 245 \taccuracy: 12.250000\n",
      "\n",
      "\n",
      "\n",
      "Filename: knn.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "   105     76.8 MiB     76.8 MiB           1   @profile\n",
      "   106                                         def preform_knn():\n",
      "   107                                             \"\"\"\n",
      "   108                                             perform KNN algorithm for each dataset with different K values\n",
      "   109                                             \"\"\"\n",
      "   110                                             \n",
      "   111                                             ## We have multiple datasets with diffrent names as Atrain.csv, Btrain.csv and etc \n",
      "   112     76.8 MiB      0.0 MiB           1       dataset_prefixes = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
      "   113                                             \n",
      "   114                                             ## read all datasets\n",
      "   115     78.9 MiB      2.1 MiB           1       train_ds_array, test_ds_array = read_dataset()\n",
      "   116                                             \n",
      "   117                                             ## dictionary history to save all\n",
      "   118     78.9 MiB      0.0 MiB           1       mdate = str(datetime.datetime.now())\n",
      "   119     78.9 MiB      0.0 MiB           1       history = {'knn.py script run date': mdate}\n",
      "   120                                             \n",
      "   121    100.1 MiB      0.0 MiB          10       for i in range(0, len(train_ds_array)):\n",
      "   122                                                 ## save the result of different K values\n",
      "   123     97.9 MiB      0.0 MiB           9           labels_classified = {}\n",
      "   124     97.9 MiB      0.0 MiB           9           features = np.array(test_ds_array[i].columns[test_ds_array[i].columns != 'label'])\n",
      "   125     97.9 MiB      0.0 MiB           9           print('Preforming %c Dataset (%cTrain.csv, %cTest.csv)' % (dataset_prefixes[i], dataset_prefixes[i], dataset_prefixes[i]))\n",
      "   126     97.9 MiB      0.0 MiB           9           print('-----------------------------------------------')\n",
      "   127                                                 \n",
      "   128    100.1 MiB      0.0 MiB          99           for K in [1, 2, 5, 10, 15, 20, 50, 100, 500, 1000]:\n",
      "   129     99.9 MiB      5.6 MiB          90               label = KNN(K, train_ds_array[i], test_ds_array[i], features)\n",
      "   130    100.1 MiB     15.6 MiB      180250               labels_classified[str(K)] = {('index_%i_classified' % i): int(l) for i,l in enumerate(label)}\n",
      "   131                                                     \n",
      "   132                                                     ## check correct classification results\n",
      "   133    100.1 MiB      0.0 MiB          90               result = check_label(label, test_ds_array[i].label)\n",
      "   134                                                     \n",
      "   135                                                     ## print the results of algorithm\n",
      "   136    100.1 MiB      0.0 MiB          90               print('K=%s ' % K, 'correctly classified count: %s' % result.sum(), '\\taccuracy: %f' % (result.sum()*100 / len(result)))        \n",
      "   137                                                           \n",
      "   138                                                 ## save each dataset histories\n",
      "   139    100.1 MiB      0.0 MiB           9           history['dataset %c' % dataset_prefixes[i]] = labels_classified    \n",
      "   140    100.1 MiB      0.0 MiB           9           print('\\n\\n')\n",
      "   141                                                 \n",
      "   142                                             ## save the results in a file\n",
      "   143    100.1 MiB      0.0 MiB           1       with open('KNN-Result.json','w') as file:\n",
      "   144    100.1 MiB      0.0 MiB           1           json.dump(history, file, indent = 4)\n",
      "   145    100.1 MiB      0.0 MiB           1       file.close()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## run the knn.py script and save the history to json file\n",
    "! python3 knn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787e1da-46af-4754-84e3-f10f75365603",
   "metadata": {},
   "source": [
    "## Appendix B\n",
    "create the confusion matrix of the results using the KNN-Result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651b0b2f-08b1-46ff-a650-0250014dc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = ''\n",
    "with open('KNN-Result.json', 'r') as json_result:\n",
    "    dict_data = json.load(json_result)\n",
    "json_result.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61a76bb-1765-4cac-87da-bf2dd2f5ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# READ DATASET #############################\n",
    "def read_csv_datasets(dataset_prefixes):\n",
    "    \"\"\"\n",
    "    read the datasets in csv format and prepare them for KNN algorithm\n",
    "    \n",
    "    INPUT:\n",
    "    -----------\n",
    "    dataset_prefixes:  An array of prefixes, example: ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
    "    \n",
    "    OUTPUTS:\n",
    "    -----------\n",
    "    train_ds_array:  the array of multiple train datasets\n",
    "    test_ds_array:  the array of multiple test datasets\n",
    "    \"\"\"\n",
    "    ## save the datasets into an array\n",
    "    train_ds_array = []\n",
    "    test_ds_array = []\n",
    "    \n",
    "    ## read them and append it to arrays\n",
    "    for char in dataset_prefixes:\n",
    "        df_train = pd.read_csv('processed_dataset/%ctrain.csv' % char)\n",
    "        df_test = pd.read_csv('processed_dataset/%ctest.csv' % char)\n",
    "        \n",
    "        train_ds_array.append(df_train)\n",
    "        test_ds_array.append(df_test)\n",
    "    \n",
    "    return train_ds_array, test_ds_array\n",
    "\n",
    "def create_confusion_matrix(actual_labels, target_labels):\n",
    "    \"\"\"\n",
    "    check the labels of the classifier output with actual data\n",
    "    \n",
    "    INPUTS:\n",
    "    -----------\n",
    "    actual_labels:  are the labels that the classifier gave us\n",
    "    target_labels:  are the correct labels of the data\n",
    "    \n",
    "    OUTPUT:\n",
    "    -----------\n",
    "    confusion_matrix:  A Dataset with with elements of TP, TN, FP, FN as True Positives, True Negatives, False Positives and False Negative\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.array(actual_labels)\n",
    "    t = np.array(target_labels)\n",
    "    \n",
    "    TP = ((a == True) & (t == True)).sum()\n",
    "    TN = ((a == False) & (t == False)).sum()\n",
    "    FP = ((a == True) & (t == False)).sum()\n",
    "    FN = ((a == False) & (t == True)).sum()\n",
    " \n",
    "    confusion_matrix = pd.DataFrame(data={'TP':[TP], 'TN': [TN], 'FP': [FP], 'FN': [FN]})\n",
    "    \n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90451a-dc53-4352-a914-7f058cf40818",
   "metadata": {},
   "source": [
    "### Now is the time to compute confusion matrix for each values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "77150d13-6d6a-46f3-a532-44abb2b057cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_values = [1, 2, 5, 10, 15, 20, 50, 100, 500, 1000]\n",
    "prefixes = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
    "\n",
    "\n",
    "ds_confusion_matrix = pd.DataFrame(columns=[ 'dataset', 'K' ,'TP', 'TN', 'FP', 'FN'])\n",
    "\n",
    "## just use the Atrain, Atest results\n",
    "for dataset_prefix in prefixes:\n",
    "\n",
    "    ## get the dataset name for json file\n",
    "    dataset_name = 'dataset %c' % dataset_prefix\n",
    "    \n",
    "    ## get the test dataframe to check the confusion matrix\n",
    "    _ , test_ds = read_csv_datasets([dataset_prefix])\n",
    "    \n",
    "    \n",
    "    ## the K value in KNN algorithm\n",
    "    for K in K_values:\n",
    "        classified_values = []\n",
    "        for j in range(0, len(dict_data[dataset_name][str(K)])):\n",
    "            values = dict_data[dataset_name][str(K)][ 'index_%i_classified' % j ]\n",
    "            classified_values.append(values)\n",
    "            \n",
    "        \n",
    "        ds = create_confusion_matrix(classified_values, test_ds[0].label)\n",
    "        ds['K'] = K\n",
    "        ds['dataset'] = dataset_prefix\n",
    "            \n",
    "        ## add the confusion matrix values into the dataframe\n",
    "        ds_confusion_matrix = ds_confusion_matrix.append(ds, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85327654-b28f-4ca5-80bf-08b84543aca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>K</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>924</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>51</td>\n",
       "      <td>949</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>73</td>\n",
       "      <td>927</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>934</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>928</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>69</td>\n",
       "      <td>931</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>73</td>\n",
       "      <td>927</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>77</td>\n",
       "      <td>923</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>903</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>881</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>272</td>\n",
       "      <td>240</td>\n",
       "      <td>760</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>132</td>\n",
       "      <td>868</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset     K   TP   TN   FP   FN\n",
       "0        A     1   77   76  924  923\n",
       "1        A     2  135   51  949  865\n",
       "2        A     5   34   73  927  966\n",
       "3        A    10   25   66  934  975\n",
       "4        A    15   18   72  928  982\n",
       "5        A    20   22   69  931  978\n",
       "6        A    50   19   73  927  981\n",
       "7        A   100   17   77  923  983\n",
       "8        A   500    7   97  903  993\n",
       "9        A  1000    4  119  881  996\n",
       "10       B     1  272  240  760  728\n",
       "11       B     2  394  132  868  606"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_confusion_matrix.head(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
