{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Using image of numbers classify them using beyes theorm. Note that here the parameters of guassian are unknown so with parameter estimation methods such as MLE, first calculate the parameters of guassian distribution and then use the beyes theorm to classify images. Divide images dataset into half training and half test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the MLE (Maximum likelihood) method we calculate the $p(D|\\theta)$ and $D = {x_1, x_2, ..., x_n}$. To find the $\\hat{\\theta}_{ML}$, we need to find the max argument of $p(D|\\theta)$. As the eqaution below:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\theta}_{ML} = argmax \\; p(D|\\theta) =>  p({x_1, x_2, ..., x_n} | \\theta) = \\prod_{i=1}^{n} p(x_i | \\theta)\n",
    "\\end{equation} \n",
    "$$\n",
    "and if we continue the equation above we will find the argmax as the derivative of $p(D|\\theta)$ with respect to $\\theta$.\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\theta}_{ML} = \\prod_{i=1}^{n} p(x_i | \\theta) \\; d\\theta = 0\n",
    "\\end{equation} \n",
    "$$\n",
    "To make it more simple we can apply the logarithm to the equation to make the product as a summation\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\theta}_{ML} = ln \\;(\\prod_{i=1}^{n} p(x_i | \\theta) \\; d\\theta) = 0 \\quad => \\quad \\hat{\\theta}_{ML} = \\sum_{i=1}^{n} ln \\; p(x_i | \\theta) \\; d\\theta = 0\n",
    "\\end{equation} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the normal distribution function and using the equation 3 we will find the mean and covariance as below:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\mu} = \\frac{1}{n} \\sum_{k=1}^{n} x_k\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\Sigma} =  \\frac{1}{n} \\sum_{k=1}^{n} (x_k - \\hat{\\mu}) (x_k - \\hat{\\mu})^t \n",
    "\\end{equation}\n",
    "$$\n",
    "So lets get to work and first calculate the $\\hat{\\mu}$ and $\\hat{\\Sigma}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5610, 257)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0          0          8          0          0          6          2   \n",
       "1          0          0          9          0          4          0   \n",
       "2          1          0          0          0          0          2   \n",
       "3          0          0          0          0          3          4   \n",
       "4          0          3          0          0          9          0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_247  feature_248  \\\n",
       "0          0          4          0         11  ...            4            5   \n",
       "1          6          6          0         10  ...            4            8   \n",
       "2          4          4          0          5  ...            4            9   \n",
       "3          2          0          0          4  ...            9            6   \n",
       "4          5          2          1          0  ...            0            0   \n",
       "\n",
       "   feature_249  feature_250  feature_251  feature_252  feature_253  \\\n",
       "0            0            0            1            0            0   \n",
       "1            0            0            9            0            4   \n",
       "2            0            0            2            0            0   \n",
       "3            0            5            1            0            0   \n",
       "4            2            4            3            0            0   \n",
       "\n",
       "   feature_254  feature_255  label  \n",
       "0            0            6      0  \n",
       "1            8            0      0  \n",
       "2            0            1      0  \n",
       "3            0            5      0  \n",
       "4            0            0      0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read dataset\n",
    "dataset = pd.read_csv('../numbers dataset/usps_images.csv')\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_dataframe(dataset, validation_split, label_string):\n",
    "    \"\"\"\n",
    "    Divide a pandas dataframe into two dataframes\n",
    "\n",
    "    INPUTS:\n",
    "    ---------\n",
    "    dataset:  the pandas dataframe that is going to be splited\n",
    "    validation_split:  the partition of how the validation set will be, example: 0.1\n",
    "    label:  For a multiclass classification, we need the label to get sample from each label (Must be an string)\n",
    "\n",
    "    OUTPUTS:\n",
    "    ---------\n",
    "    train_set:  pandas dataframe, the partition of training set\n",
    "    valid_set:  pandas dataframe, the partition of validation set  \n",
    "    \"\"\"\n",
    "\n",
    "    assert ((validation_split >0) & (validation_split < 1)), \"[ERROR] validation_split must be between 0 and 1!\"\n",
    "    columns = dataset.columns\n",
    "    train_images = pd.DataFrame(columns=columns)\n",
    "    validation_images = pd.DataFrame(columns=columns)\n",
    "\n",
    "    ## get all labels for training and test data\n",
    "    for label in dataset[label_string].unique():\n",
    "        ## get the dataset for each dataset label\n",
    "        dataset_label = dataset[dataset[label_string] == label]\n",
    "        length = int(len(dataset_label) * validation_split)\n",
    "\n",
    "        train_images = train_images.append(dataset_label.iloc[: length], ignore_index=True)\n",
    "        validation_images = validation_images.append(dataset_label.iloc[length: ], ignore_index=True)\n",
    "\n",
    "    features = columns[:len(columns) - 1]\n",
    "\n",
    "    ## normalize the values into float\n",
    "    ## we need to convert the integer values to float for KNN function\n",
    "    for col in features:\n",
    "        train_images[col] = pd.to_numeric(train_images[col], downcast='float')\n",
    "        validation_images[col] = pd.to_numeric(validation_images[col], downcast='float')\n",
    "\n",
    "    return train_images, validation_images\n",
    "\n",
    "df_train, df_test = divide_dataframe(dataset, 0.5, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN MEAN shape:  (256,)\n",
      "TEST MEAN shape:  (256,)\n",
      "train Sigma_hat shape:  (256, 256)\n",
      "test Sigma_hat shape:  (256, 256)\n"
     ]
    }
   ],
   "source": [
    "def mu_hat(x_vectors):\n",
    "    \"\"\"\"\n",
    "    find the mu hat from Maximum likelihood, using the equation 4\n",
    "\n",
    "    INPUTS:\n",
    "    -------\n",
    "    x_vectors:  a pandas dataframe of features\n",
    "\n",
    "    OUTPUT:\n",
    "    ---------\n",
    "    mu_hat:  the mean for all data\n",
    "    \"\"\"\n",
    "\n",
    "    sum = 0\n",
    "    for i in range(0, len(x_vectors)):\n",
    "        sum += x_vectors.iloc[i]\n",
    "    \n",
    "    mu_hat = (1 / len(x_vectors)) * sum\n",
    "\n",
    "    return mu_hat\n",
    "\n",
    "def Sigma_hat(mu, x_vectors):\n",
    "    \"\"\"\n",
    "    calculate the covariance estimation using Maximum likelihood, the equation 5\n",
    "\n",
    "    INPUTS:\n",
    "    --------\n",
    "    mu:  the mu value of each class\n",
    "    x_vectors:  a pandas dataframe of features\n",
    "\n",
    "    OUTPUT:\n",
    "    --------\n",
    "    Sigma:  the covarince matrixes of dataset\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((256, 256))\n",
    "    matrix_values = []\n",
    "    for i in range(0, len(x_vectors)):\n",
    "        ## features must be a column vector\n",
    "        X = x_vectors.iloc[i].T\n",
    "\n",
    "        ## to make the array as column vector, we again need to transpose it\n",
    "        subtract = np.array([X - mu]).T\n",
    "\n",
    "        value = np.dot(subtract.T, subtract) \n",
    "        \n",
    "        matrix_values += value\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "features = df_train.columns[df_train.columns != 'label']\n",
    "train_mean = mu_hat(df_train[features])\n",
    "test_mean = mu_hat(df_test[features])\n",
    "\n",
    "train_Sigma = Sigma_hat(train_mean, df_train[features])\n",
    "test_Sigma = Sigma_hat(test_mean, df_test[features])\n",
    "\n",
    "\n",
    "print(\"TRAIN MEAN shape: \", train_mean.shape)\n",
    "print(\"TEST MEAN shape: \", test_mean.shape )\n",
    "\n",
    "print(\"train Sigma_hat shape: \", np.array(train_Sigma).shape)\n",
    "print(\"test Sigma_hat shape: \", np.array(test_Sigma).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to create the classifier function. We will use the multivariate gaussian distribution function. We had written the function in Question 2 so we just coppied it. (we ade just some minor changes to support as many features as available )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the probability of x using the x value\n",
    "def guassian_multivariate(mu ,Sigma, X):\n",
    "    \"\"\"\n",
    "    calculate the probability of multivariate guassian\n",
    "    we have a feature space of 2 by 1\n",
    "\n",
    "    INPUTS:\n",
    "    --------\n",
    "    mu:  is the mean value \n",
    "    Sigma:  covariance matrix\n",
    "    X:  feature array\n",
    "\n",
    "    OUTPUT:\n",
    "    -------\n",
    "    probability:  A scalar value representing the probability of X features \n",
    "    \"\"\"\n",
    "    # covariance determanant\n",
    "    det_Sigma = np.linalg.det(Sigma)\n",
    "\n",
    "    coefficient = 1 / 2 * np.pi\n",
    "\n",
    "    ## inverse of covariance matrix\n",
    "    if(det_Sigma != 0):\n",
    "        Sigma_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "        ## exponential power value ( the superscript) \n",
    "        e_superscript =  (-1/2) * np.dot((X - mu).T , Sigma_inv ).dot(X - mu) \n",
    "        e_superscript = np.array(e_superscript, dtype=np.float128)\n",
    "\n",
    "        e = np.exp(e_superscript)\n",
    "\n",
    "\n",
    "        probability = coefficient * np.sqrt(det_Sigma) * e\n",
    "    \n",
    "    ## the probabilty of -1 means we couldn't find the inverse matrix\n",
    "    else:\n",
    "        probability = -1\n",
    "\n",
    "    return probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1, -1]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = []\n",
    "for idx in range(0, len(df_train)):\n",
    "    probability = guassian_multivariate(train_mean, train_Sigma, df_train[features].iloc[idx])\n",
    "    probabilities.append(probability)\n",
    "## check a portion of probabilities\n",
    "probabilities[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This part is NOT USEFULE!, was made before finding determinant of zero (will be removed in the next commit)** <br>\n",
    "As we can see here we got overflow for it. So to find the probability for the classes we can apply the logarithm to it. \n",
    "The logarithm applied to guassian multivariate distribution function will be like below:\n",
    "$$\n",
    "\\begin{equation}\n",
    "g(x) = - \\frac{1}{2} (x - \\mu_i)^t \\Sigma^{-1} (x-\\mu_i) - \\frac{d}{2} ln(2\\pi) - \\frac{1}{2} ln |\\Sigma_i| \n",
    "\\end{equation}\n",
    "$$\n",
    "<!-- Some of the formulation in the above equation is not necessery because we're comparing two classes and they are constants. So the equation we need to implement is:\n",
    "$$\n",
    "\\begin{equation}\n",
    "g(x) = - \\frac{1}{2} (x - \\mu_i)^t \\Sigma^{-1} (x-\\mu_i) - \\frac{1}{2} ln |\\Sigma_i| \n",
    "\\end{equation}\n",
    "$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the probability of x using the x value\n",
    "def guassian_multivariate_using_discriminant_function(mu ,Sigma, X):\n",
    "    \"\"\"\n",
    "    calculate the probability of multivariate guassian using the logarithm discriminant function\n",
    "    we have a feature space of 2 by 1\n",
    "\n",
    "    INPUTS:\n",
    "    --------\n",
    "    mu:  is the mean value \n",
    "    Sigma:  covariance matrix\n",
    "    X:  feature arrays\n",
    "\n",
    "    OUTPUT:\n",
    "    -------\n",
    "    probability:  A scalar value representing the probability of X features \n",
    "    \"\"\"\n",
    "      \n",
    "    \n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "\n",
    "    part1 =  (-1/2) * np.dot((X - mu).T , Sigma_inv ).dot(X - mu) \n",
    "\n",
    "    # covariance determanant\n",
    "    det_Sigma = np.linalg.det(Sigma)\n",
    "\n",
    "    part2 = (-1/2) * np.log1p(2*np.pi) * len(X)\n",
    "\n",
    "    part3 = (-1 /2) * np.log1p(det_Sigma)\n",
    "        \n",
    "    result = part1 + part2 + part3\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amin/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:2158: RuntimeWarning: overflow encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    }
   ],
   "source": [
    "# result_prob = []\n",
    "# for idx in range(0, len(df_train)):\n",
    "#     probability = guassian_multivariate(train_mean, np.array(train_Sigma, dtype=np.float64), df_train[features].iloc[idx])\n",
    "#     result_prob.append(probability)\n",
    "# np.array(result_prob).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       ...,\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we hitted with infinity values for results. This is the result of matrix determinant that is equal to infinity, So we need another method to calculate the parameters of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_classified_classes(results, dataset_label):\n",
    "    \"\"\"\n",
    "    check positive or negative values for the result and return the accuracy\n",
    "\n",
    "    INPUT:\n",
    "    -------\n",
    "    results:  numpy array contaning positive and negative values\n",
    "    dataset_label:  numpy array containing the target classes\n",
    "\n",
    "    OUTPUT:\n",
    "    ---------\n",
    "    accuracy:  the accuracy of the classification\n",
    "    \"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A = np.log(np.array(train_Sigma, dtype=np.float32))\n",
    "# A = A.round(2)\n",
    "# np.linalg.det(A)\n",
    "np.linalg.det(train_Sigma)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
